{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding activity 1: Nearest neighbor smoothers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor smoothers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write a nearest neighbor smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nns(xis, yis, x):\n",
    "    \"\"\"Return yis[i], where xis[i] is the entry of xis closest to x.\"\"\"\n",
    "    \n",
    "    # Your code goes here.\n",
    "    \n",
    "    return yis[i]\n",
    "\n",
    "# (Check) Should print 6 666 666 6666.\n",
    "xis = [0, 1, 5, 6.5]\n",
    "yis = [6, 66, 666, 6666]\n",
    "print(nns(xis, yis, -1), nns(xis, yis, 4), nns(xis, yis, 5.1), nns(xis, yis, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a \"vectorized\" nearest neighbor smoother.\n",
    "\n",
    "Your solution here should be independent of your solution to the previous exercise.\n",
    "The naming clash is intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nns(xis, yis, xs):\n",
    "    \"\"\"Same as nns, but returning a list of ys given a list of xs.\"\"\"\n",
    "    \n",
    "    # Your code goes here. Don't invoke code from the previous exercise.\n",
    "\n",
    "    return ys\n",
    "\n",
    "# (Check) Should print [   6  666  666 6666].\n",
    "xis = np.array([0, 1, 5, 6.5])\n",
    "yis = np.array([6, 66, 666, 6666])\n",
    "print(nns(xis, yis, [-1, 4, 5.1, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a \"higher order\" smoother function, i.e., a function that takes training data as input and return a function to evaluate on test data. Are there advantages to such an implementation over that of the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nns_factory(xis, yis):\n",
    "    def nns(xs):\n",
    "        \n",
    "        # Your code goes here. Don't invoke code from previous exercises.\n",
    "        \n",
    "        return ys\n",
    "    return nns\n",
    "\n",
    "# (Check) Should print [   6  666  666 6666].\n",
    "xis = np.array([0, 1, 5, 6.5])\n",
    "yis = np.array([6, 66, 666, 6666])\n",
    "nns = nns_factory(xis, yis)\n",
    "print(nns([-1, 4, 5.1, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't consider the \"higher order function\" pattern from the previous exercise to be particularly pythonic, you aren't alone. Let's write a class offering the same functionality, in the <code>sklearn</code> style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class NNS(RegressorMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Check that X and y have compatible shapes.\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        # Store the training data on the instance. (Why?)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        ### Your code goes here.\n",
    "\n",
    "        # Return the instance. (Why?)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Check is fit had been called.\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        \n",
    "        # Validate input type.\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Your code goes here.\n",
    "        \n",
    "        return y\n",
    "    \n",
    "# (Check) Should print [6, 666, 666, 6666].\n",
    "X = np.array([0, 1, 5, 6.5]).reshape((-1, 1))\n",
    "y = np.array([6, 66, 666, 6666])\n",
    "X_test = np.array([-1, 4, 5.1, 100]).reshape(-1, 1)\n",
    "S = NNS().fit(X, y)\n",
    "print(S.predict(X_test))\n",
    "print(NNS()\n",
    "      .fit([0, 1, 5, 6.5], [6, 66, 666, 6666])\n",
    "      .predict([-1, 4, 5.1, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens if you remove the `.reshape(-1, 1)` method call in the definition of `X` and run the above cell again?\n",
    "\n",
    "- If you inspect the methods available on `S` by typing `S.<tab>`, you'll notice a `score` method.\n",
    "  - Where did it come from? What does it do? Find out by typing `S.score?<ctrl+enter>` or, on a mac, `S.score?<command+enter>`. (`<command+enter>` is a jupyter keyboard shortcut for running the current cell.)\n",
    "  - Try it out! You'll need to provide `y`-values to go with the `x`-values in `X_test`.\n",
    "  - Look at the source code of `RegressorMixin`. (Where is it?) Notice that the implementation of the `score` method invokes `predict`, which we have thoughfully provided. According to the <a href=\"https://scikit-learn.org/stable/glossary.html#term-regressors\"><code>sklearn</code> docs</a>, a *regressor* is a class that implements `fit`, `predict`, and `score`. (Duck typing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
