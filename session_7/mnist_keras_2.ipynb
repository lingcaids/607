{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 34s 564us/sample - loss: 2.2753 - accuracy: 0.1683 - val_loss: 2.2391 - val_accuracy: 0.3271\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 34s 559us/sample - loss: 2.2165 - accuracy: 0.2747 - val_loss: 2.1668 - val_accuracy: 0.4912\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 34s 574us/sample - loss: 2.1396 - accuracy: 0.3672 - val_loss: 2.0692 - val_accuracy: 0.6088\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 34s 569us/sample - loss: 2.0375 - accuracy: 0.4420 - val_loss: 1.9406 - val_accuracy: 0.6715\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 35s 575us/sample - loss: 1.9059 - accuracy: 0.5069 - val_loss: 1.7758 - val_accuracy: 0.7285\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 33s 551us/sample - loss: 1.7489 - accuracy: 0.5619 - val_loss: 1.5802 - val_accuracy: 0.7712\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 34s 571us/sample - loss: 1.5747 - accuracy: 0.6034 - val_loss: 1.3723 - val_accuracy: 0.7958\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 34s 569us/sample - loss: 1.4027 - accuracy: 0.6356 - val_loss: 1.1781 - val_accuracy: 0.8130\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 35s 576us/sample - loss: 1.2585 - accuracy: 0.6630 - val_loss: 1.0169 - val_accuracy: 0.8234\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 33s 544us/sample - loss: 1.1392 - accuracy: 0.6842 - val_loss: 0.8919 - val_accuracy: 0.8319\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 34s 574us/sample - loss: 1.0470 - accuracy: 0.6991 - val_loss: 0.7969 - val_accuracy: 0.8378\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 32s 538us/sample - loss: 0.9724 - accuracy: 0.7172 - val_loss: 0.7241 - val_accuracy: 0.8445\n",
      "Test loss: 0.7241442280769348\n",
      "Test accuracy: 0.8445\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
